import openai
import logging
import re
import json
import io
import base64
import os
from functools import lru_cache
from decimal import Decimal
from datetime import datetime
from typing import List, Dict, Optional, Any, Tuple
from pathlib import Path

# Imports database
from config.database import get_db_connection, get_db, CustomSQLDatabase, get_db_cursor,get_schema

# Imports agent modules
from agent.llm_utils import ask_llm 
from langchain.prompts import PromptTemplate
from agent.template_matcher.matcher import SemanticTemplateMatcher
from agent.cache_manager import CacheManager
from agent.cache_manager1 import CacheManager1
from agent.pdf_utils.bulletin import export_bulletin_pdf
from agent.pdf_utils.attestation import PDFGenerator

# Imports security and templates
from agent.prompts.templates import PROMPT_TEMPLATE, ADMIN_PROMPT_TEMPLATE, PARENT_PROMPT_TEMPLATE
from security.roles import is_super_admin, is_parent, validate_parent_access, is_admin, validate_admin_access

# Imports for graphs and data processing
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
from tabulate import tabulate
import MySQLdb
import traceback

from agent.conversation_history import ConversationHistory

# Configure matplotlib for server environment
matplotlib.use('Agg')  
plt.switch_backend('Agg')

# Configure logging
logger = logging.getLogger(__name__)

class SQLAssistant:
    """
    Assistant SQL unifi√© combinant les fonctionnalit√©s de SQLAssistant et SQLAgent
    Capable de g√©n√©rer du SQL, ex√©cuter les requ√™tes, cr√©er des graphiques et r√©pondre en langage naturel
    """
    
    def __init__(self, db=None, model="gpt-4o", temperature=0.3, max_tokens=500):
        # Configuration base
        self.db = db if db is not None else get_db_connection()
        self.model = model
        self.temperature = temperature
        self.max_tokens = max_tokens
        
        # Historique et cache
        self.last_generated_sql = ""
        self.query_history = []
        self.conversation_history = []
        self.cache = CacheManager()
        self.cache1 = CacheManager1()
        
        # Configuration des co√ªts et sch√©ma
        self.cost_per_1k_tokens = 0.005
        self.schema = self._safe_get_schema()
        
        # Chargement des configurations
        self.relations_description = self._safe_load_relations()
        self.domain_descriptions = self._safe_load_domain_descriptions()
        self.domain_to_tables_mapping = self._safe_load_domain_to_tables_mapping()
        self.ask_llm = ask_llm
        
        # Template matcher et templates questions
        self.template_matcher = SemanticTemplateMatcher()
        self.templates_questions = self._safe_load_templates()
        self.last_generated_sql = ""
        self.query_history = []
        self.conversation_history_old = []  # Renommer pour √©viter confusion

        
        # üÜï NOUVEAU : Gestionnaire d'historique persistant
        self.conversation_manager = ConversationHistory()
        
        logger.info("‚úÖ SQLAssistant initialis√© avec succ√®s")

    # ================================
    # M√âTHODES DE CHARGEMENT S√âCURIS√âES
    # ================================
    
    def _safe_get_schema(self):
        """R√©cup√®re le sch√©ma de base de donn√©es de mani√®re s√©curis√©e"""
        try:
            return self.db.get_schema() if self.db else []
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Impossible de r√©cup√©rer le sch√©ma: {e}")
            return []

    def _safe_load_relations(self) -> str:
        """Charge les relations avec gestion d'erreurs"""
        try:
            relations_path = Path(__file__).parent  / 'prompts' / 'relations.txt'
            if relations_path.exists():
                return relations_path.read_text(encoding='utf-8')
            logger.warning("‚ö†Ô∏è Fichier relations.txt non trouv√©")
            return "# Aucune relation d√©finie"
        except Exception as e:
            logger.error(f"‚ùå Erreur chargement relations: {e}")
            return "# Erreur chargement relations"

    def _safe_load_domain_descriptions(self) -> dict:
        """Charge les descriptions de domaine avec gestion d'erreurs"""
        try:
            domain_path = Path(__file__).parent  / 'prompts' / 'domain_descriptions.json'
            if domain_path.exists():
                with open(domain_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            logger.warning("‚ö†Ô∏è Fichier domain_descriptions.json non trouv√©")
            return {}
        except Exception as e:
            logger.error(f"‚ùå Erreur chargement domain descriptions: {e}")
            return {}

    def _safe_load_domain_to_tables_mapping(self) -> dict:
        """Charge le mapping domaine-tables avec gestion d'erreurs"""
        try:
            mapping_path = Path(__file__).parent   / 'prompts' / 'domain_tables_mapping.json'
            if mapping_path.exists():
                with open(mapping_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            logger.warning("‚ö†Ô∏è Fichier domain_tables_mapping.json non trouv√©")
            return {}
        except Exception as e:
            logger.error(f"‚ùå Erreur chargement domain mapping: {e}")
            return {}

    def _safe_load_templates(self) -> list:
        """Charge les templates de questions avec gestion d'erreurs"""
        try:
            templates_path = Path(__file__).parent/ 'templates_questions.json'
            
            if not templates_path.exists():
                logger.info(f"‚ö†Ô∏è Fichier non trouv√©, cr√©ation: {templates_path}")
                templates_path.write_text('{"questions": []}', encoding='utf-8')
                return []

            content = templates_path.read_text(encoding='utf-8').strip()
            if not content:
                logger.warning("‚ö†Ô∏è Fichier vide, r√©initialisation")
                templates_path.write_text('{"questions": []}', encoding='utf-8')
                return []

            try:
                data = json.loads(content)
                if not isinstance(data.get("questions", []), list):
                    raise ValueError("Format invalide: 'questions' doit √™tre une liste")
                
                valid_templates = []
                for template in data["questions"]:
                    if all(key in template for key in ["template_question", "requete_template"]):
                        valid_templates.append(template)
                    else:
                        logger.warning(f"‚ö†Ô∏è Template incomplet ignor√©: {template.get('description', 'sans description')}")
                
                if valid_templates:
                    self.template_matcher.load_templates(valid_templates)
                    logger.info(f"‚úÖ {len(valid_templates)} templates charg√©s")
                
                return valid_templates

            except json.JSONDecodeError as e:
                logger.error(f"‚ùå Fichier JSON corrompu, r√©initialisation. Erreur: {e}")
                backup_path = templates_path.with_suffix('.bak.json')
                templates_path.rename(backup_path)
                templates_path.write_text('{"questions": []}', encoding='utf-8')
                return []

        except Exception as e:
            logger.error(f"‚ùå Erreur critique lors du chargement: {e}")
            return []

    # ================================
    # M√âTHODES PRINCIPALES D'INTERACTION
    # ================================

    
    # def ask_question(self, question: str, user_id: Optional[int] = None, roles: Optional[List[str]] = None) -> tuple[str, str, Optional[str]]:
    #     """
    #     Point d'entr√©e principal pour poser une question
    #     Retourne (sql_query, formatted_response, graph_data)
    #     """
    #     if user_id is None:
    #         user_id = 0
    #     if roles is None:
    #         roles = []

    #     # Validation des r√¥les
    #     if not roles:
    #         return "", "‚ùå Acc√®s refus√© : Aucun r√¥le fourni", None
        
    #     valid_roles = ['ROLE_SUPER_ADMIN', 'ROLE_PARENT']
    #     has_valid_role = any(role in valid_roles for role in roles)
        
    #     if not has_valid_role:
    #         return "", f"‚ùå Acc√®s refus√© : R√¥les fournis {roles}, requis {valid_roles}", None

    #     # Traitement par r√¥le
    #     try:
    #         if 'ROLE_SUPER_ADMIN' in roles:
    #             return self._process_super_admin_question(question)  # Retourne 3 valeurs
    #         elif 'ROLE_PARENT' in roles:
    #             return self._process_parent_question(question, user_id)  # Retourne 3 valeurs
    #     except Exception as e:
    #         logger.error(f"Erreur dans ask_question: {e}")
    #         return "", f"‚ùå Erreur : {str(e)}", None

    def ask_question_with_history(self, question: str, user_id: Optional[int] = None, 
                                 roles: Optional[List[str]] = None, 
                                 conversation_id: Optional[int] = None) -> tuple[str, str, Optional[str], int]:
        """
        Version am√©lior√©e qui sauvegarde automatiquement dans l'historique
        Retourne (sql_query, formatted_response, graph_data, conversation_id)
        """
        if user_id is None:
            user_id = 0
        if roles is None:
            roles = []

        # Validation des r√¥les (identique √† la version existante)
        if not roles:
            return "", "‚ùå Acc√®s refus√© : Aucun r√¥le fourni", None, 0
        
        valid_roles = ['ROLE_SUPER_ADMIN', 'ROLE_PARENT']
        has_valid_role = any(role in valid_roles for role in roles)
        
        if not has_valid_role:
            return "", f"‚ùå Acc√®s refus√© : R√¥les fournis {roles}, requis {valid_roles}", None, 0

        try:
            # üÜï GESTION DE LA CONVERSATION
            if conversation_id is None:
                conversation_id = self.conversation_manager.create_conversation(user_id, question)
            
            # Sauvegarder la question utilisateur
            self.conversation_manager.add_message(conversation_id, 'user', question)

            # Traitement par r√¥le (utiliser les m√©thodes existantes)
            if 'ROLE_SUPER_ADMIN' in roles:
                sql_query, formatted_response, graph_data = self._process_super_admin_question(question)
            elif 'ROLE_PARENT' in roles:
                sql_query, formatted_response, graph_data = self._process_parent_question(question, user_id)
            
            # üÜï SAUVEGARDER LA R√âPONSE ASSISTANT
            self.conversation_manager.add_message(
                conversation_id, 
                'assistant', 
                formatted_response, 
                sql_query, 
                graph_data
            )
            
            logger.info(f"‚úÖ Question trait√©e et sauvegard√©e - Conversation {conversation_id}")
            return sql_query, formatted_response, graph_data, conversation_id
            
        except Exception as e:
            logger.error(f"Erreur dans ask_question_with_history: {e}")
            error_message = f"‚ùå Erreur : {str(e)}"
            
            # Sauvegarder l'erreur aussi
            if conversation_id:
                self.conversation_manager.add_message(conversation_id, 'system', error_message)
            
            return "", error_message, None, conversation_id or 0

    
    def _process_super_admin_question(self, question: str) -> tuple[str, str, Optional[str]]:
        """Traite une question avec acc√®s admin complet - CORRIG√â POUR RETOURNER 3 VALEURS"""
        
        # 1. V√©rifier le cache
        cached = self.cache.get_cached_query(question)
        if cached:
            sql_template, variables = cached
            sql_query = sql_template
            for column, value in variables.items():
                sql_query = sql_query.replace(f"{{{column}}}", value)
            
            logger.info("‚ö° Requ√™te admin r√©cup√©r√©e depuis le cache")
            try:
                result = self.execute_sql_query(sql_query)
                if result['success']:
                    # üéØ G√âN√âRATION DE GRAPHIQUE POUR CACHE
                    graph_data = self.generate_graph_if_relevant(result['data'], question)
                    formatted_result = self.format_response_with_ai(result['data'], question, sql_query)
                    return sql_query, formatted_result, graph_data  # üéØ 3 VALEURS
                else:
                    return sql_query, f"‚ùå Erreur d'ex√©cution SQL : {result['error']}", None
            except Exception as db_error:
                return sql_query, f"‚ùå Erreur d'ex√©cution SQL : {str(db_error)}", None
        
        # 2. V√©rifier les templates existants
        template_match = self.find_matching_template(question)
        if template_match:
            logger.info("üîç Template admin trouv√©")
            sql_query = self.generate_query_from_template(
                template_match["template"],
                template_match["variables"]
            )
            try:
                result = self.execute_sql_query(sql_query)
                if result['success']:
                    # üéØ G√âN√âRATION DE GRAPHIQUE POUR TEMPLATE
                    graph_data = self.generate_graph_if_relevant(result['data'], question)
                    formatted_result = self.format_response_with_ai(result['data'], question, sql_query)
                    return sql_query, formatted_result, graph_data  # üéØ 3 VALEURS
                else:
                    return sql_query, f"‚ùå Erreur d'ex√©cution SQL : {result['error']}", None
            except Exception as db_error:
                return sql_query, f"‚ùå Erreur d'ex√©cution SQL : {str(db_error)}", None
        
        # 3. G√©n√©ration AI + ex√©cution + formatage
        try:
            # üéØ G√âN√âRATION SQL MANQUANTE - AJOUT ICI
            sql_query = self.generate_sql_with_ai(question)
            
            if not sql_query:
                return "", "‚ùå La requ√™te g√©n√©r√©e est vide.", None
                
            result = self.execute_sql_query(sql_query)
            if result['success']:
                # üéØ G√âN√âRATION DE GRAPHIQUE
                graph_data = self.generate_graph_if_relevant(result['data'], question)
                
                formatted_result = self.format_response_with_ai(result['data'], question, sql_query)
                self.cache.cache_query(question, sql_query)
                
                return sql_query, formatted_result, graph_data  # üéØ 3 VALEURS
            else:
                # Tentative de correction automatique
                corrected_sql = self._auto_correct_sql(sql_query, result['error'])
                if corrected_sql:
                    retry_result = self.execute_sql_query(corrected_sql)
                    if retry_result['success']:
                        graph_data = self.generate_graph_if_relevant(retry_result['data'], question)
                        formatted_result = self.format_response_with_ai(retry_result['data'], question, corrected_sql)
                        return corrected_sql, formatted_result, graph_data  # üéØ 3 VALEURS
                
                return sql_query, f"‚ùå Erreur d'ex√©cution SQL : {result['error']}", None
            
        except Exception as e:
            logger.error(f"Erreur dans _process_super_admin_question: {e}")
            return "", f"‚ùå Erreur de traitement : {str(e)}", None    
    
    def _process_parent_question(self, question: str, user_id: int) -> tuple[str, str, Optional[str]]:
        """Traite une question avec restrictions parent - CORRIG√â POUR RETOURNER 3 VALEURS"""
        
        # Nettoyage du cache
        self.cache1.clean_double_braces_in_cache()
        
        # V√©rification cache parent
        cached = self.cache1.get_cached_query(question, user_id)
        if cached:
            sql_template, variables = cached
            sql_query = sql_template
            for column, value in variables.items():
                sql_query = sql_query.replace(f"{{{column}}}", value)
            
            logger.info("‚ö° Requ√™te parent r√©cup√©r√©e depuis le cache")
            try:
                result = self.execute_sql_query(sql_query)
                if result['success']:
                    # üéØ G√âN√âRATION DE GRAPHIQUE POUR CACHE
                    graph_data = self.generate_graph_if_relevant(result['data'], question)
                    formatted_result = self.format_response_with_ai(result['data'], question, sql_query)
                    return sql_query, formatted_result, graph_data  # üéØ 3 VALEURS
                else:
                    return sql_query, f"‚ùå Erreur d'ex√©cution SQL : {result['error']}", None
            except Exception as db_error:
                return sql_query, f"‚ùå Erreur d'ex√©cution SQL : {str(db_error)}", None

        # R√©cup√©ration des donn√©es enfants
        children_ids, children_prenoms = self.get_user_children_data(user_id)
        children_ids_str = ", ".join(map(str, children_ids))
        children_names_str = ", ".join(children_prenoms)
        
        if not children_ids:
            return "", "‚ùå Aucun enfant trouv√© pour ce parent ou erreur d'acc√®s.", None
        
        logger.info(f"üîí Restriction parent - Enfants autoris√©s: {children_ids}")

        # Validation des noms dans la question
        detected_names = self.detect_names_in_question(question, children_prenoms)
        if detected_names["unauthorized_names"]:
            unauthorized_list = ", ".join(detected_names["unauthorized_names"])
            return "", f"‚ùå Acc√®s interdit: Vous n'avez pas le droit de consulter les donn√©es de {unauthorized_list}", None
        
        # G√©n√©ration SQL avec template parent
        try:
            sql_query = self.generate_sql_parent(question, user_id, children_ids_str, children_names_str)
            
            if not sql_query:
                return "", "‚ùå La requ√™te g√©n√©r√©e est vide.", None

            # Validation de s√©curit√© (sauf pour infos publiques)
            if not self._is_public_info_query(question, sql_query):
                if not self.validate_parent_access(sql_query, children_ids):
                    return "", "‚ùå Acc√®s refus√©: La requ√™te ne respecte pas les restrictions parent.", None
            else:
                logger.info("‚ÑπÔ∏è Question sur information publique - validation bypass√©e")

            # Ex√©cution
            result = self.execute_sql_query(sql_query)
            
            if result['success']:
                # üéØ G√âN√âRATION DE GRAPHIQUE
                graph_data = self.generate_graph_if_relevant(result['data'], question)
                formatted_result = self.format_response_with_ai(result['data'], question, sql_query)
                self.cache1.cache_query(question, sql_query)
                return sql_query, formatted_result, graph_data  # üéØ 3 VALEURS
            else:
                return sql_query, f"‚ùå Erreur d'ex√©cution SQL : {result['error']}", None
                
        except Exception as e:
            logger.error(f"Erreur dans _process_parent_question: {e}")
            return "", f"‚ùå Erreur de traitement : {str(e)}", None
    
    # ================================
    # G√âN√âRATION SQL
    # ================================

    def generate_sql_with_ai(self, question: str) -> str:
        """G√©n√®re une requ√™te SQL via IA pour admin"""
        relevant_domains = self.get_relevant_domains(question, self.domain_descriptions)
        
        if relevant_domains:
            relevant_tables = self.get_tables_from_domains(relevant_domains, self.domain_to_tables_mapping)
            table_info = self.db.get_table_info(relevant_tables)
            relevant_domain_descriptions = "\n".join(
                f"{dom}: {self.domain_descriptions[dom]}" for dom in relevant_domains if dom in self.domain_descriptions
            )
        else:
            table_info = self.db.get_table_info()
            relevant_domain_descriptions = "\n".join(self.domain_descriptions.values())

        prompt = ADMIN_PROMPT_TEMPLATE.format(
            input=question,
            table_info=table_info,
            relevant_domain_descriptions=relevant_domain_descriptions,
            relations=self.relations_description
        )

        llm_response = self.ask_llm(prompt)
        sql_query = self._clean_sql(llm_response)
        sql_query = self._auto_fix_quotes_in_sql(sql_query)
        
        # Validation
        try:
            self._validate_sql(sql_query)
            self.last_generated_sql = sql_query
            return sql_query
        except Exception as e:
            logger.error(f"Erreur validation SQL: {e}")
            raise ValueError(f"Requ√™te SQL invalide: {str(e)}")

    def generate_sql_parent(self, question: str, user_id: int, children_ids_str: str, children_names_str: str) -> str:
        """G√©n√®re une requ√™te SQL avec restrictions parent"""
        relevant_domains = self.get_relevant_domains(question, self.domain_descriptions)
        
        if relevant_domains:
            relevant_tables = self.get_tables_from_domains(relevant_domains, self.domain_to_tables_mapping)
            table_info = self.db.get_table_info(relevant_tables)
            relevant_domain_descriptions = "\n".join(
                f"{dom}: {self.domain_descriptions[dom]}" for dom in relevant_domains if dom in self.domain_descriptions
            )
        else:
            table_info = self.db.get_table_info()
            relevant_domain_descriptions = "\n".join(self.domain_descriptions.values())

        prompt = PARENT_PROMPT_TEMPLATE.format(
            input=question,
            table_info=table_info,
            relevant_domain_descriptions=relevant_domain_descriptions,
            relations=self.relations_description,
            user_id=user_id,
            children_ids=children_ids_str,
            children_names=children_names_str
        )
        
        llm_response = self.ask_llm(prompt)
        sql_query = self._clean_sql(llm_response)
        
        # Validation
        try:
            self._validate_sql(sql_query)
            self.last_generated_sql = sql_query
            return sql_query
        except Exception as e:
            logger.error(f"Erreur validation SQL parent: {e}")
            raise ValueError(f"Requ√™te SQL invalide: {str(e)}")

    def _clean_sql(self, text: str) -> str:
        """Nettoie et extrait le SQL du texte g√©n√©r√© par l'IA"""
        if not text:
            return ""
        
        sql = re.sub(r'```(sql)?|```', '', text)
        sql = re.sub(r'(?i)^\s*(?:--|#).*$', '', sql, flags=re.MULTILINE)
        return sql.strip().rstrip(';')

    
    def _validate_sql(self, sql: str) -> bool:
        """Valide la syntaxe SQL et v√©rifie la s√©curit√©"""
        if not sql:
            raise ValueError("‚ùå Requ√™te SQL vide")
            
        sql_lower = sql.lower()

        # Protection contre les requ√™tes destructives
        forbidden_keywords = ['drop', 'delete', 'update', 'insert', ';--', 'exec', 'truncate']
        if any(keyword in sql_lower for keyword in forbidden_keywords):
            raise ValueError("‚ùå Commande SQL dangereuse d√©tect√©e")

        # V√©rification que c'est bien une requ√™te SELECT
        if not sql_lower.strip().startswith('select'):
            raise ValueError("‚ùå Seules les requ√™tes SELECT sont autoris√©es")

        # ‚úÖ SUPPRIME LA VALIDATION EXPLAIN QUI CAUSE LE PROBL√àME
        # L'ex√©cution r√©elle se fera dans execute_sql_query() qui g√®re mieux les erreurs
        
        return True
    
    def _validate_sql_semantics(self, sql: str, question: str) -> bool:
        """Valide la coh√©rence s√©mantique entre question et SQL"""
        
        # Mappings question ‚Üí table attendue
        expected_mappings = {
            'section': ['section'],
            'civilit√©': ['civilite'],
            'nationalit√©': ['nationalite'],
            'niveau': ['niveau'],
            '√©l√®ve': ['eleve', 'personne', 'inscriptioneleve'],
            'classe': ['classe'],
            'localit√©': ['localite']
        }
        
        question_lower = question.lower()
        sql_lower = sql.lower()
        
        # V√©rifier que les tables correspondent √† la question
        for keyword, expected_tables in expected_mappings.items():
            if keyword in question_lower:
                if not any(table in sql_lower for table in expected_tables):
                    raise ValueError(f"Question sur '{keyword}' mais table correspondante absente")
        
        return True
    
    # ================================
    # EX√âCUTION SQL
    # ================================
    def execute_sql_query(self, sql_query: str) -> dict:
        """Ex√©cute une requ√™te SQL et retourne les r√©sultats"""
        try:
            if not sql_query:
                return {"success": False, "error": "Requ√™te SQL vide", "data": []}
            
            # ‚úÖ FIX: Utiliser directement get_db() au lieu de CustomSQLDatabase
            connection = get_db()
            cursor = connection.cursor()
            
            logger.debug(f"üîç Ex√©cution SQL: {sql_query}")
            cursor.execute(sql_query)
            
            # ‚úÖ FIX: R√©cup√©ration correcte des colonnes et donn√©es
            columns = [desc[0] for desc in cursor.description]
            results = cursor.fetchall()
            
            logger.debug(f"üîç Colonnes: {columns}")
            logger.debug(f"üîç R√©sultats bruts: {results}")
            
            # ‚úÖ FIX: Construction correcte des dictionnaires
            data = []
            for row in results:
                if isinstance(row, dict):
                    # Si row est d√©j√† un dict (DictCursor)
                    data.append(row)
                else:
                    # Si row est un tuple, cr√©er le dict
                    data.append(dict(zip(columns, row)))
            
            logger.debug(f"üîç Donn√©es finales: {data}")
            
            cursor.close()
            
            # Fermer la connexion si c'est une connexion directe
            if hasattr(connection, '_direct_connection'):
                connection.close()
            
            # S√©rialiser les donn√©es
            serialized_data = self._serialize_data(data)
            
            return {"success": True, "data": serialized_data}
            
        except Exception as e:
            logger.error(f"‚ùå Erreur ex√©cution SQL: {e}")
            logger.error(f"‚ùå SQL qui a √©chou√©: {sql_query}")
            return {"success": False, "error": str(e), "data": []}
    def _serialize_data(self, data):
        """S√©rialise les donn√©es pour √©viter les probl√®mes de types"""
        if isinstance(data, (list, tuple)):
            return [self._serialize_data(item) for item in data]
        elif isinstance(data, dict):
            return {key: self._serialize_data(value) for key, value in data.items()}
        elif hasattr(data, 'isoformat'):
            return data.isoformat()
        elif isinstance(data, Decimal):
            return float(data)
        return data

    # ================================
    # FORMATAGE DES R√âPONSES
    # ================================

    def format_response_with_ai(self, data: List[Dict], question: str, sql_query: str) -> str:
        """Version am√©lior√©e du formatage avec debug"""
        
        logger.debug(f"üîç Formatage - Donn√©es re√ßues: {data}")
        
        if not data:
            return "‚úÖ Requ√™te ex√©cut√©e mais aucun r√©sultat trouv√©."
        
        # Cas sp√©ciaux avec v√©rification des donn√©es r√©elles
        if len(data) == 1 and len(data[0]) == 1:
            first_item = data[0]
            column_name = list(first_item.keys())[0]
            value = list(first_item.values())[0]
            
            logger.debug(f"üîç Une valeur - Colonne: {column_name}, Valeur: {value}, Type: {type(value)}")
            
            # ‚úÖ FIX: V√©rification plus stricte
            if value is None or str(value).strip() == "" or str(value) == column_name:
                return "‚ùå Erreur dans les donn√©es : Les r√©sultats semblent corrompus ou vides."
            
            # Am√©liorer la r√©ponse selon le contexte
            if "combien" in question.lower() or "nombre" in question.lower():
                if "√©l√®ve" in question.lower():
                    return f"Il y a {value} √©l√®ves inscrits cette ann√©e."
                elif "inscription" in question.lower():
                    return f"Il y a {value} inscriptions enregistr√©es."
                else:
                    return f"Nombre trouv√© : {value}"
            else:
                return f"R√©sultat : {value}"
        
        # Pour les listes multiples
        try:
            df = pd.DataFrame(data)
            
            # Formatage normal avec IA
            messages = [
                {
                    "role": "system",
                    "content": """Analysez les donn√©es SQL et donnez une r√©ponse claire en fran√ßais. 
                    Pr√©sentez les r√©sultats de mani√®re structur√©e et utile."""
                },
                {
                    "role": "user",
                    "content": f"Question: {question}\n\nDonn√©es: {json.dumps(data[:10], ensure_ascii=False)}"
                }
            ]
            
            response = openai.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.2,
                max_tokens=400
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"Erreur formatage: {e}")
            return self._format_simple_response(data, question)
    def _format_simple_response(self, data: List[Dict], question: str) -> str:
        """Formatage simple sans IA en cas d'erreur"""
        if not data:
            return "‚úÖ Requ√™te ex√©cut√©e mais aucun r√©sultat trouv√©."
        
        # Cas sp√©cial: une seule valeur num√©rique (COUNT, etc.)
        if len(data) == 1 and len(data[0]) == 1:
            value = list(data[0].values())[0]
            if isinstance(value, (int, float)) and value is not None:
                if "combien" in question.lower() or "nombre" in question.lower():
                    if "√©l√®ve" in question.lower() or "eleve" in question.lower():
                        return f"Il y a {value} √©l√®ves."
                    elif "absence" in question.lower():
                        return f"Nombre d'absences : {value}"
                    else:
                        return f"R√©sultat : {value}"
                else:
                    return f"R√©sultat : {value}"
        
        # Cas g√©n√©ral: tableau
        try:
            df = pd.DataFrame(data)
            table = tabulate(df.head(20), headers='keys', tablefmt='grid', showindex=False)
            
            result = f"R√©sultats pour: {question}\n\n{table}"
            if len(data) > 20:
                result += f"\n\n... et {len(data) - 20} autres r√©sultats"
            
            return result
            
        except Exception:
            # Ultimate fallback
            return f"R√©sultats trouv√©s: {len(data)} √©l√©ments"
    def _auto_fix_quotes_in_sql(self, sql: str) -> str:
        """Corrige automatiquement les guillemets manquants dans les requ√™tes SQL"""
        
        # Pattern pour d√©tecter les valeurs alphanum√©riques sans guillemets apr√®s =, IN, etc.
        patterns = [
            # Cas: WHERE colonne = valeur_alphanum
            (r'(\w+\s*=\s*)([A-Za-z][A-Za-z0-9]*\b)(?!\s*[,)])', r"\1'\2'"),
            # Cas: WHERE colonne = valeur avec chiffres et lettres
            (r'(\w+\s*=\s*)([0-9][A-Za-z0-9]*\b)', r"\1'\2'"),
            # Cas: IN (valeur1, valeur2)
            (r'(\bIN\s*\(\s*)([A-Za-z0-9][A-Za-z0-9]*)', r"\1'\2'"),
        ]
        
        corrected_sql = sql
        for pattern, replacement in patterns:
            corrected_sql = re.sub(pattern, replacement, corrected_sql, flags=re.IGNORECASE)
        
        return corrected_sql
    # ================================
    # G√âN√âRATION DE GRAPHIQUES
    # ================================

    def generate_graph_if_relevant(self, data: List[Dict], question: str) -> Optional[str]:
        """G√©n√®re un graphique si pertinent pour les donn√©es"""
        if not data or len(data) < 2:
            return None
            
        try:
            df = pd.DataFrame(data)
            
            # D√©tection automatique du type de graphique
            graph_type = self.detect_graph_type(question, df.columns.tolist())
            
            if graph_type and len(df) >= 2:
                return self.generate_auto_graph(df, graph_type)
                
        except Exception as e:
            logger.error(f"Erreur g√©n√©ration graphique: {e}")
            
        return None

    def detect_graph_type(self, user_query: str, df_columns: List[str]) -> Optional[str]:
        """D√©tecte le type de graphique appropri√© - VERSION AM√âLIOR√âE"""
        user_query = user_query.lower()
        columns = [col.lower() for col in df_columns]
        
        # üéØ D√âTECTION SP√âCIFIQUE pour √©volution/courbe
        evolution_keywords = ["√©volution", "evolution", "courbe", "tendance", "historique", 
                            "progression", "croissance", "d√©veloppement", "trend"]
        
        if any(keyword in user_query for keyword in evolution_keywords):
            # V√©rifier si on a une colonne temporelle
            temporal_cols = [col for col in columns if any(t in col for t in ["annee", "ann√©e", "year", "date", "mois", "month"])]
            if temporal_cols:
                return "line"
        
        # D√©tection r√©partition/pie
        if any(k in user_query for k in ["r√©partition", "repartition", "pourcentage", "ratio", "proportion"]):
            return "pie"
        
        # D√©tection comparaison/bar
        if any(k in user_query for k in ["comparaison", "comparer", "nombre", "count", "somme", "total"]):
            # Si c'est temporel, pr√©f√©rer line
            temporal_cols = [col for col in columns if any(t in col for t in ["annee", "ann√©e", "year", "date"])]
            if temporal_cols and any(k in user_query for k in ["√©volution", "evolution", "courbe", "tendance"]):
                return "line"
            else:
                return "bar"
        
        # D√©tection automatique bas√©e sur les donn√©es
        numeric_cols = len([col for col in df_columns if any(num in col.lower() for num in ["count", "nombre", "total", "somme"])])
        if numeric_cols >= 1:
            temporal_cols = [col for col in columns if any(t in col for t in ["annee", "ann√©e", "year", "date"])]
            if temporal_cols:
                return "line"
            else:
                return "bar"
        
        return None
    def generate_auto_graph(self, df: pd.DataFrame, graph_type: str = None) -> Optional[str]:
        """G√©n√®re automatiquement un graphique - VERSION AM√âLIOR√âE"""
        if df.empty or len(df) < 2:
            logger.debug("‚ùå DataFrame vide ou insuffisant")
            return None
            
        try:
            # Nettoyage des donn√©es
            df = df.dropna()
            
            if len(df) < 2:
                logger.debug("‚ùå Donn√©es insuffisantes apr√®s nettoyage")
                return None
            
            logger.debug(f"üîç G√©n√©ration graphique - Type: {graph_type}")
            logger.debug(f"üîç Colonnes DataFrame: {df.columns.tolist()}")
            logger.debug(f"üîç Premi√®res lignes:\n{df.head()}")
            
            # üéØ D√âTECTION AM√âLIOR√âE du type de graphique
            if not graph_type:
                # Identifier colonnes temporelles et num√©riques
                temporal_cols = [col for col in df.columns if any(t in col.lower() for t in ["annee", "ann√©e", "year", "date", "mois", "month"])]
                numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
                
                logger.debug(f"üîç Auto-d√©tection - Temporel: {temporal_cols}, Num√©rique: {numeric_cols}")
                
                if temporal_cols and numeric_cols:
                    graph_type = "line"  # Privil√©gier ligne pour donn√©es temporelles
                elif len(df) <= 7 and len(numeric_cols) >= 1:
                    graph_type = "pie"
                else:
                    graph_type = "bar"
            
            # Configuration du graphique
            plt.figure(figsize=(12, 7))
            plt.style.use('default')
            
            # üéØ AM√âLIORATION : Graphique en ligne pour √©volution
            if graph_type == "line" and len(df.columns) >= 2:
                # Identifier les colonnes
                temporal_col = None
                numeric_col = None
                
                # üéØ AM√âLIORATION : Chercher colonne temporelle avec plus de flexibilit√©
                for col in df.columns:
                    col_lower = col.lower()
                    if any(t in col_lower for t in ["annee", "ann√©e", "year", "date", "an"]) or col_lower in ["annee", "ann√©e"]:
                        temporal_col = col
                        break
                
                # Chercher colonne num√©rique
                numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
                if numeric_cols:
                    # Prioriser les colonnes avec des mots-cl√©s pertinents
                    priority_keywords = ["inscription", "total", "count", "nombre", "somme"]
                    for keyword in priority_keywords:
                        matching_cols = [col for col in numeric_cols if keyword in col.lower()]
                        if matching_cols:
                            numeric_col = matching_cols[0]
                            break
                    
                    if not numeric_col:
                        numeric_col = numeric_cols[0]
                
                # Si pas de colonne temporelle trouv√©e, prendre la premi√®re
                if not temporal_col:
                    temporal_col = df.columns[0]
                if not numeric_col:
                    numeric_col = df.columns[1]
                
                logger.debug(f"üéØ Colonnes s√©lectionn√©es - Temporel: {temporal_col}, Num√©rique: {numeric_col}")
                
                # Trier par ordre temporel
                df_sorted = df.sort_values(by=temporal_col)
                
                # üéØ V√âRIFICATION des donn√©es
                x_data = df_sorted[temporal_col]
                y_data = df_sorted[numeric_col]
                
                logger.debug(f"üéØ Donn√©es X: {x_data.tolist()}")
                logger.debug(f"üéØ Donn√©es Y: {y_data.tolist()}")
                
                # Cr√©er le graphique
                plt.plot(x_data, y_data, 
                        marker='o', linewidth=3, markersize=8, 
                        color='#2E86AB', markerfacecolor='#A23B72')
                
                plt.title(f"√âvolution des {numeric_col} par {temporal_col}", fontsize=16, fontweight='bold', pad=20)
                plt.xlabel(temporal_col, fontsize=12, fontweight='bold')
                plt.ylabel(numeric_col, fontsize=12, fontweight='bold')
                plt.xticks(rotation=45, fontsize=10)
                plt.yticks(fontsize=10)
                plt.grid(True, alpha=0.3, linestyle='--')
                
                # Ajouter les valeurs sur les points
                for i, (x, y) in enumerate(zip(x_data, y_data)):
                    plt.annotate(f'{y}', (x, y), textcoords="offset points", 
                            xytext=(0,10), ha='center', fontsize=9, fontweight='bold')
            
            # üéØ AUTRES TYPES DE GRAPHIQUES (pie, bar) - garder le code existant
            elif graph_type == "pie" and len(df.columns) >= 2:
                x_col = df.columns[0]
                y_col = df.columns[1]
                
                if not pd.api.types.is_numeric_dtype(df[y_col]):
                    logger.debug(f"‚ùå Colonne {y_col} n'est pas num√©rique")
                    return None
                    
                df_pie = df.nlargest(8, y_col)
                colors = plt.cm.Set3(range(len(df_pie)))
                
                plt.pie(df_pie[y_col], labels=df_pie[x_col], autopct='%1.1f%%', 
                    startangle=90, colors=colors, textprops={'fontsize': 10})
                plt.title(f"R√©partition par {x_col}", fontsize=16, fontweight='bold')
                
            elif graph_type == "bar" and len(df.columns) >= 2:
                x_col = df.columns[0]
                y_cols = [col for col in df.columns[1:] if pd.api.types.is_numeric_dtype(df[col])]
                
                if not y_cols:
                    logger.debug("‚ùå Aucune colonne num√©rique pour bar chart")
                    return None
                
                df_bar = df.nlargest(15, y_cols[0]) if len(df) > 15 else df
                
                if len(y_cols) == 1:
                    bars = plt.bar(df_bar[x_col], df_bar[y_cols[0]], 
                                color='#2E86AB', alpha=0.8, edgecolor='white', linewidth=1)
                    plt.title(f"Comparaison de {y_cols[0]} par {x_col}", fontsize=16, fontweight='bold')
                    
                    # Ajouter valeurs sur les barres
                    for bar in bars:
                        height = bar.get_height()
                        plt.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                                f'{int(height)}', ha='center', va='bottom', fontweight='bold')
                else:
                    df_bar.plot.bar(x=x_col, y=y_cols, alpha=0.8, ax=plt.gca())
                    plt.title(f"Comparaison par {x_col}", fontsize=16, fontweight='bold')
                    
                plt.xlabel(x_col, fontsize=12, fontweight='bold')
                plt.ylabel('Valeurs', fontsize=12, fontweight='bold')
                plt.xticks(rotation=45, fontsize=10)
                plt.grid(True, alpha=0.3, axis='y', linestyle='--')
            
            else:
                logger.debug(f"‚ùå Type de graphique non support√© ou donn√©es insuffisantes: {graph_type}")
                return None
            
            plt.tight_layout()
            
            # üéØ AM√âLIORATION : Meilleure qualit√© d'image
            img = io.BytesIO()
            plt.savefig(img, format='png', bbox_inches='tight', dpi=150, 
                    facecolor='white', edgecolor='none')
            img.seek(0)
            encoded = base64.b64encode(img.getvalue()).decode('utf-8')
            plt.close()
            
            logger.info(f"üìä Graphique {graph_type} g√©n√©r√© avec succ√®s")
            return f"data:image/png;base64,{encoded}"
            
        except Exception as e:
            logger.error(f"Erreur g√©n√©ration graphique: {str(e)}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            plt.close('all')
            return None
    # ================================
    # CORRECTION AUTOMATIQUE SQL
    # ================================

    def _auto_correct_sql(self, bad_sql: str, error_msg: str) -> Optional[str]:
        """Tente de corriger automatiquement une requ√™te SQL d√©faillante"""
        try:
            correction_prompt = f"""
            Vous √™tes un expert SQL. Corrigez cette requ√™te MySQL en vous basant sur l'erreur.
            
            Erreur: {error_msg}
            
            Requ√™te incorrecte:
            ```sql
            {bad_sql}
            ```
            
            Sch√©ma disponible:
            ```json
            {json.dumps(self.schema[:10], indent=2)}
            ```
            
            R√®gles:
            - G√©n√©rez UNIQUEMENT du SQL valide
            - Pas d'explications, juste la requ√™te corrig√©e
            - Utilisez SELECT uniquement
            
            Requ√™te corrig√©e:
            ```sql
            """
            
            response = openai.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": correction_prompt}],
                temperature=0,
                max_tokens=300
            )
            
            corrected_sql = self._clean_sql(response.choices[0].message.content)
            
            if corrected_sql and self._validate_sql(corrected_sql):
                logger.info("‚úÖ Requ√™te SQL corrig√©e avec succ√®s")
                return corrected_sql
                
        except Exception as e:
            logger.error(f"Correction SQL √©chou√©e: {str(e)}")
            
        return None

    # ================================
    # M√âTHODES UTILITAIRES
    # ================================

    def get_relevant_domains(self, query: str, domain_descriptions: Dict[str, str]) -> List[str]:
        """Identifie les domaines pertinents bas√©s sur la question"""
        domain_desc_str = "\n".join([f"- {name}: {desc}" for name, desc in domain_descriptions.items()])
        domain_prompt_content = f"""
        Based on the following user question, identify ALL relevant domains from the list below.
        Return only the names of the relevant domains, separated by commas. If no domain is relevant, return 'None'.

        User Question: {query}

        Available Domains and Descriptions:
        {domain_desc_str}

        Relevant Domains (comma-separated):
        """
        
        try:
            response = self.ask_llm(domain_prompt_content)
            domain_names = response.strip()
            
            if domain_names.lower() == 'none' or not domain_names:
                return []
                
            return [d.strip() for d in domain_names.split(',')]
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'identification des domaines: {e}")
            return []
    def get_relevant_domains_improved(self, query: str) -> List[str]:
        """Version am√©lior√©e de la d√©tection des domaines"""
        
        # Mappings directs question ‚Üí domaine
        direct_mappings = {
            'section': ['GENERAL_ADMINISTRATION_CONFIG'],
            'civilit√©': ['GENERAL_ADMINISTRATION_CONFIG'],
            'nationalit√©': ['GENERAL_ADMINISTRATION_CONFIG'],
            'niveau': ['GENERAL_ADMINISTRATION_CONFIG'],
            '√©l√®ve': ['ELEVES_INSCRIPTIONS'],
            'inscription': ['ELEVES_INSCRIPTIONS'],
            'classe': ['GENERAL_ADMINISTRATION_CONFIG'],
            'localit√©': ['GENERAL_ADMINISTRATION_CONFIG'],
            'gouvernorat': ['GENERAL_ADMINISTRATION_CONFIG'],
            '√©tablissement': ['GENERAL_ADMINISTRATION_CONFIG']
        }
        
        query_lower = query.lower()
        relevant_domains = set()
        
        # Recherche directe
        for keyword, domains in direct_mappings.items():
            if keyword in query_lower:
                relevant_domains.update(domains)
        
        # Si aucun domaine trouv√©, utiliser l'IA
        if not relevant_domains:
            return self.get_relevant_domains(query, self.domain_descriptions)
    
        return list(relevant_domains)
    def get_tables_from_domains(self, domains: List[str], domain_to_tables_map: Dict[str, List[str]]) -> List[str]:
        """R√©cup√®re toutes les tables associ√©es aux domaines donn√©s"""
        tables = []
        for domain in domains:
            tables.extend(domain_to_tables_map.get(domain, []))
        return sorted(list(set(tables)))

    def find_matching_template(self, question: str) -> Optional[Dict[str, Any]]:
        """Trouve un template correspondant √† la question"""
        exact_match = self._find_exact_template_match(question)
        if exact_match:
            return exact_match
        
        semantic_match, score = self.template_matcher.find_similar_template(question)
        if semantic_match:
            logger.info(f"üîç Template s√©mantiquement similaire trouv√© (score: {score:.2f})")
            return self._extract_variables(question, semantic_match)
        
        return None

    def _find_exact_template_match(self, question: str) -> Optional[Dict[str, Any]]:
        """Trouve un template exact"""
        cleaned_question = question.rstrip(' ?')
        for template in self.templates_questions:
            pattern = template["template_question"]
            regex_pattern = re.sub(r'\{(.+?)\}', r'(?P<\1>.+?)', pattern)
            match = re.fullmatch(regex_pattern, cleaned_question, re.IGNORECASE)
            if match:
                variables = {k: v.strip() for k, v in match.groupdict().items()}
                return {
                    "template": template,
                    "variables": variables if variables else {}
                }
        return None

    def _extract_variables(self, question: str, template: Dict) -> Dict[str, Any]:
        """Extrait les variables d'un template s√©mantique"""
        # Impl√©mentation simplifi√©e - peut √™tre am√©lior√©e
        return {
            "template": template,
            "variables": {}
        }

    def generate_query_from_template(self, template: Dict, variables: Dict) -> str:
        """G√©n√®re une requ√™te √† partir d'un template et de variables"""
        sql_template = template["requete_template"]
        
        # Remplace les variables dans le template
        for var_name, var_value in variables.items():
            placeholder = f"{{{var_name}}}"
            sql_template = sql_template.replace(placeholder, str(var_value))
        
        return sql_template

    # ================================
    # M√âTHODES SP√âCIFIQUES AUX PARENTS
    # ================================

    def get_user_children_data(self, user_id: int) -> Tuple[List[int], List[str]]:
        """R√©cup√®re les donn√©es des enfants pour un parent"""
        connection = None
        cursor = None
        children_ids = []
        children_prenoms = []

        try:
            query = """
            SELECT DISTINCT pe.id AS id_enfant, pe.PrenomFr AS prenom
            FROM personne p
            JOIN parent pa ON p.id = pa.Personne
            JOIN parenteleve pev ON pa.id = pev.Parent
            JOIN eleve e ON pev.Eleve = e.id
            JOIN personne pe ON e.IdPersonne = pe.id
            WHERE p.id = %s
            """
            
            connection = get_db()
            cursor = connection.cursor()
            
            cursor.execute(query, (user_id,))
            children = cursor.fetchall()
            
            if children:
                children_ids = [child['id_enfant'] for child in children]
                children_prenoms = [child['prenom'] for child in children]
                logger.info(f"‚úÖ Found {len(children_ids)} children for parent {user_id}")
            
            return (children_ids, children_prenoms)
            
        except Exception as e:
            logger.error(f"‚ùå Error getting children data for parent {user_id}: {str(e)}")
            return ([], [])
            
        finally:
            try:
                if cursor:
                    cursor.close()
                    
                if connection and hasattr(connection, '_direct_connection'):
                    connection.close()
                    logger.debug("üîå Closed direct MySQL connection")
            except Exception as close_error:
                logger.warning(f"‚ö†Ô∏è Error during cleanup: {str(close_error)}")

    def detect_names_in_question(self, question: str, authorized_names: List[str]) -> Dict[str, List[str]]:
        """D√©tecte les noms dans une question et v√©rifie les autorisations"""
        import unicodedata
        
        def normalize_name(name):
            name = unicodedata.normalize('NFD', name.lower())
            return ''.join(char for char in name if unicodedata.category(char) != 'Mn')
        
        normalized_authorized = [normalize_name(name) for name in authorized_names]
        
        # Mots √† exclure
        excluded_words = {
            'mon', 'ma', 'mes', 'le', 'la', 'les', 'de', 'du', 'des', 'et', 'ou', 'si', 'ce', 
            'cette', 'ces', 'son', 'sa', 'ses', 'notre', 'nos', 'votre', 'vos', 'leur', 'leurs',
            'enfant', 'enfants', 'fils', 'fille', 'gar√ßon', 'petit', 'petite', 'grand', 'grande',
            'eleve', '√©l√®ve', 'eleves', '√©l√®ves', 'classe', '√©cole', 'ecole', 'moyenne', 'note', 
            'notes', 'r√©sultat', 'resultats', 'trimestre', 'ann√©e', 'annee', 'mati√®re', 'matiere',
            'emploi', 'temps', 'horaire', 'professeur', 'enseignant', 'directeur', 'principal'
        }
        
        # Extraire les noms potentiels (commence par majuscule)
        potential_names = re.findall(r'\b[A-Z√Ä√Å√Ç√É√Ñ√Ö√Ü√á√à√â√ä√ã√å√ç√é√è√ê√ë√í√ì√î√ï√ñ√ò√ô√ö√õ√ú√ù√û≈∏][a-z√†√°√¢√£√§√•√¶√ß√®√©√™√´√¨√≠√Æ√Ø√∞√±√≤√≥√¥√µ√∂√∏√π√∫√ª√º√Ω√æ√ø]+', question)
        
        # Filtrer les mots exclus
        potential_names = [name for name in potential_names if normalize_name(name) not in excluded_words]
        
        authorized_found = []
        unauthorized_found = []
        
        for name in potential_names:
            normalized_name = normalize_name(name)
            if normalized_name in normalized_authorized:
                authorized_found.append(name)
            else:
                # Mots fran√ßais communs √† ignorer
                common_words = {'Merci', 'Bonjour', 'Salut', 'Cordialement', 'Madame', 'Monsieur', 
                              'Mademoiselle', 'Docteur', 'Professeur', 'Janvier', 'F√©vrier', 'Mars', 
                              'Avril', 'Mai', 'Juin', 'Juillet', 'Ao√ªt', 'Septembre', 'Octobre', 
                              'Novembre', 'D√©cembre', 'Lundi', 'Mardi', 'Mercredi', 'Jeudi', 
                              'Vendredi', 'Samedi', 'Dimanche', 'France', 'Tunisie', 'Fran√ßais'}
                
                if name not in common_words:
                    unauthorized_found.append(name)
        
        logger.debug(f"üîç Pr√©noms d√©tect√©s - Autoris√©s: {authorized_found}, Non autoris√©s: {unauthorized_found}")
        
        return {
            "authorized_names": authorized_found,
            "unauthorized_names": unauthorized_found
        }

    def validate_parent_access(self, sql_query: str, children_ids: List[int]) -> bool:
        """Valide qu'une requ√™te parent respecte les restrictions de s√©curit√©"""
        if not isinstance(children_ids, list) or not children_ids:
            return False
            
        try:
            children_ids_str = [str(int(id)) for id in children_ids]
        except (ValueError, TypeError):
            raise ValueError("Tous les IDs enfants doivent √™tre num√©riques")
        
        # Normalisation de la requ√™te
        sql_lower = sql_query.lower().replace("\n", " ").replace("\t", " ")
        sql_lower = re.sub(r'\s+', ' ', sql_lower).strip()
        
        logger.debug(f"üîç SQL normalis√©: {sql_lower}")
        logger.debug(f"üë∂ IDs enfants: {children_ids_str}")
        
        # Patterns de s√©curit√© √† rechercher
        security_patterns = set()
        
        # Filtres directs
        for child_id in children_ids_str:
            security_patterns.update({
                f"idpersonne = {child_id}",
                f"idpersonne={child_id}",
                f"e.idpersonne = {child_id}",
                f"e.idpersonne={child_id}",
                f"eleve.idpersonne = {child_id}",
                f"eleve.idpersonne={child_id}",
                f"idpersonne in ({child_id})",
                f"e.idpersonne in ({child_id})",
                f"eleve.idpersonne in ({child_id})"
            })
        
        # Pour listes d'IDs
        if len(children_ids_str) > 1:
            ids_joined = ",".join(children_ids_str)
            ids_joined_spaced = ", ".join(children_ids_str)
            security_patterns.update({
                f"idpersonne in ({ids_joined})",
                f"idpersonne in ({ids_joined_spaced})",
                f"e.idpersonne in ({ids_joined})",
                f"e.idpersonne in ({ids_joined_spaced})",
                f"eleve.idpersonne in ({ids_joined})",
                f"eleve.idpersonne in ({ids_joined_spaced})"
            })
        
        # Sous-requ√™tes de s√©curit√©
        for child_id in children_ids_str:
            security_patterns.update({
                f"eleve in (select id from eleve where idpersonne = {child_id}",
                f"eleve in (select id from eleve where idpersonne={child_id}",
                f"exists (select 1 from eleve where idpersonne = {child_id}",
                f"exists (select 1 from eleve where idpersonne={child_id}"
            })
        
        # V√©rification des patterns
        found_patterns = [pattern for pattern in security_patterns if pattern in sql_lower]
        
        if not found_patterns:
            logger.warning(f"Requ√™te parent non s√©curis√©e - Filtre enfants manquant: {sql_query}")
            return False
        
        # V√©rification des patterns interdits
        forbidden_patterns = {"--", "/*", "*/", " drop ", " truncate ", " insert ", " update ", " delete "}
        found_forbidden = [pattern for pattern in forbidden_patterns if pattern in sql_lower]
        
        if found_forbidden:
            logger.error(f"Tentative de requ√™te non autoris√©e d√©tect√©e: {found_forbidden}")
            return False
        
        logger.debug("‚úÖ Validation parent r√©ussie")
        return True

    def _is_public_info_query(self, question: str, sql_query: str) -> bool:
        """V√©rifie si la question concerne des informations publiques"""
        question_lower = question.lower()
        sql_lower = sql_query.lower()
        
        # Mots-cl√©s pour informations publiques
        public_keywords = ['cantine', 'repas', 'menu', 'd√©jeuner', 'restauration', 
                          'actualit√©', 'actualite', 'actualit√©s', 'actualites', 
                          'nouvelles', 'informations', 'annonces']
        
        # Tables publiques
        public_tables = ['cantine', 'menu', 'actualite', 'actualite1', 'annonces']
        
        # V√©rifications
        has_public_keywords = any(keyword in question_lower for keyword in public_keywords)
        has_public_tables = any(table in sql_lower for table in public_tables)
        
        return has_public_keywords or has_public_tables

    # ================================
    # M√âTHODES POUR DOCUMENTS PDF
    # ================================

    def get_student_info_by_name(self, full_name: str) -> Optional[Dict]:
        """R√©cup√®re les informations d'un √©l√®ve par son nom complet"""
        try:
            conn = get_db()
            cursor = conn.cursor(MySQLdb.cursors.DictCursor)

            sql = """
            SELECT 
                p.NomFr, p.PrenomFr,
                CONCAT(p.NomFr, ' ', p.PrenomFr) AS nom_complet,
                e.DateNaissance, IFNULL(e.LieuNaissance, e.AutreLieuNaissance) AS lieu_de_naissance,
                c.CODECLASSEFR as classe, n.NOMNIVAR as niveau,
                e.id as eleve_id, e.IdPersonne as matricule, 
                e.idedusrv as id_service,
                ie.id as inscription_id
            FROM eleve e
            JOIN personne p ON e.IdPersonne = p.id
            JOIN inscriptioneleve ie ON e.id = ie.Eleve
            JOIN classe c ON ie.Classe = c.id
            JOIN niveau n ON c.IDNIV = n.id
            JOIN anneescolaire a ON ie.AnneeScolaire = a.id
            WHERE LOWER(CONCAT(p.NomFr, ' ', p.PrenomFr)) = LOWER(%s)
            AND a.AnneeScolaire = %s
            LIMIT 1
            """

            current_year = "2024/2025"  
            cursor.execute(sql, (full_name, current_year))
            row = cursor.fetchone()
            
            return row

        except Exception as e:
            logger.error(f"Erreur get_student_info_by_name: {str(e)}")
            return None
        finally:
            try:
                if cursor:
                    cursor.close()
                if conn and hasattr(conn, '_direct_connection'):
                    conn.close()
            except:
                pass

    # ================================
    # M√âTHODES DE NETTOYAGE
    # ================================

    def cleanup_conversation_history(self, max_messages: int = 10):
        """Nettoie l'historique des conversations"""
        if len(self.conversation_history) > max_messages:
            # Garder les messages syst√®me et les plus r√©cents
            system_messages = [msg for msg in self.conversation_history if msg.get('role') == 'system']
            recent_messages = self.conversation_history[-(max_messages-len(system_messages)):]
            self.conversation_history = system_messages + recent_messages

    def reset_conversation(self):
        """Reset l'historique des conversations"""
        self.conversation_history = []
        self.query_history = []
        logger.info("üîÑ Historique des conversations r√©initialis√©")

    # ================================
    # FONCTIONS UTILITAIRES GLOBALES
    # ================================

    def validate_name(name: str) -> bool:
        """Valide si un nom contient seulement des caract√®res autoris√©s"""
        if not name or not isinstance(name, str):
            return False
        
        pattern = r"^[A-Za-z√Ä-√ø\s\-']+$"
        
        name = name.strip()
        if len(name) < 2 or len(name) > 100:
            return False
        
        # Pas d'espaces multiples ou de caract√®res sp√©ciaux en d√©but/fin
        if re.search(r"\s{2,}|^[\s\-']|[\s\-']$", name):
            return False
        
        return bool(re.match(pattern, name))
    
    def get_user_conversations(self, user_id: int, limit: int = 50) -> List[Dict]:
        """R√©cup√®re les conversations d'un utilisateur"""
        try:
            return self.conversation_manager.get_user_conversations(user_id, limit)
        except Exception as e:
            logger.error(f"Erreur r√©cup√©ration conversations: {e}")
            return []

    def get_conversation_messages(self, conversation_id: int, user_id: int) -> List[Dict]:
        """R√©cup√®re les messages d'une conversation"""
        try:
            return self.conversation_manager.get_conversation_messages(conversation_id, user_id)
        except Exception as e:
            logger.error(f"Erreur r√©cup√©ration messages: {e}")
            return []

    def search_conversations(self, user_id: int, query: str, limit: int = 20) -> List[Dict]:
        """Recherche dans les conversations"""
        try:
            return self.conversation_manager.search_conversations(user_id, query, limit)
        except Exception as e:
            logger.error(f"Erreur recherche conversations: {e}")
            return []

    def update_conversation_title(self, conversation_id: int, user_id: int, new_title: str) -> bool:
        """Met √† jour le titre d'une conversation"""
        try:
            return self.conversation_manager.update_conversation_title(conversation_id, user_id, new_title)
        except Exception as e:
            logger.error(f"Erreur mise √† jour titre: {e}")
            return False

    def delete_conversation(self, conversation_id: int, user_id: int) -> bool:
        """Supprime une conversation"""
        try:
            return self.conversation_manager.delete_conversation(conversation_id, user_id)
        except Exception as e:
            logger.error(f"Erreur suppression conversation: {e}")
            return False

    def get_user_stats(self, user_id: int) -> Dict:
        """R√©cup√®re les statistiques d'un utilisateur"""
        try:
            return self.conversation_manager.get_user_stats(user_id)
        except Exception as e:
            logger.error(f"Erreur statistiques utilisateur: {e}")
            return {}

    # üÜï M√âTHODE POUR MIGRER L'HISTORIQUE EXISTANT
    def migrate_existing_conversations(self, user_id: int, old_messages: List[Dict]) -> Optional[int]:
        """Migre une conversation existante vers le nouveau syst√®me d'historique"""
        try:
            if not old_messages:
                return None
                
            # Cr√©er une nouvelle conversation
            first_message = old_messages[0].get('text', 'Conversation migr√©e')
            conversation_id = self.conversation_manager.create_conversation(user_id, first_message)
            
            # Migrer tous les messages
            for msg in old_messages:
                message_type = 'user' if msg.get('isMe', False) else 'assistant'
                content = msg.get('text', '')
                sql_query = msg.get('sqlQuery')
                graph_data = msg.get('graphBase64')
                
                self.conversation_manager.add_message(
                    conversation_id, message_type, content, sql_query, graph_data
                )
            
            logger.info(f"‚úÖ {len(old_messages)} messages migr√©s vers conversation {conversation_id}")
            return conversation_id
            
        except Exception as e:
            logger.error(f"Erreur migration conversation: {e}")
            return None

    # üîÑ M√âTHODE DE COMPATIBILIT√â : Wrapper pour l'ancienne m√©thode
    def ask_question(self, question: str, user_id: Optional[int] = None, 
                    roles: Optional[List[str]] = None) -> tuple[str, str, Optional[str]]:
        """
        M√©thode de compatibilit√© qui utilise le nouveau syst√®me avec historique
        Retourne (sql_query, formatted_response, graph_data)
        """
        sql_query, formatted_response, graph_data, _ = self.ask_question_with_history(
            question, user_id, roles
        )
        return sql_query, formatted_response, graph_data

    # üÜï NETTOYAGE P√âRIODIQUE DE L'HISTORIQUE
    def cleanup_user_history(self, user_id: int, keep_recent_days: int = 30) -> int:
        """Nettoie l'historique ancien d'un utilisateur en gardant les conversations r√©centes"""
        try:
            from datetime import datetime, timedelta
            
            cutoff_date = datetime.now() - timedelta(days=keep_recent_days)
            
            # R√©cup√©rer les conversations anciennes
            all_conversations = self.conversation_manager.get_user_conversations(user_id, limit=1000)
            old_conversations = [
                conv for conv in all_conversations 
                if datetime.fromisoformat(conv['updated_at']) < cutoff_date
            ]
            
            # Archiver les anciennes conversations
            deleted_count = 0
            for conv in old_conversations:
                if self.conversation_manager.delete_conversation(conv['id'], user_id):
                    deleted_count += 1
            
            logger.info(f"üßπ {deleted_count} conversations anciennes archiv√©es pour utilisateur {user_id}")
            return deleted_count
            
        except Exception as e:
            logger.error(f"Erreur nettoyage historique utilisateur: {e}")
            return 0

    # üÜï EXPORT/IMPORT DE CONVERSATIONS
    def export_conversation(self, conversation_id: int, user_id: int, format: str = 'json') -> Optional[str]:
        """Exporte une conversation dans diff√©rents formats"""
        try:
            messages = self.conversation_manager.get_conversation_messages(conversation_id, user_id)
            if not messages:
                return None
            
            if format == 'json':
                import json
                return json.dumps(messages, indent=2, ensure_ascii=False)
            
            elif format == 'txt':
                output = []
                for msg in messages:
                    timestamp = msg.get('timestamp', '')
                    msg_type = msg.get('type', '').upper()
                    content = msg.get('content', '')
                    output.append(f"[{timestamp}] {msg_type}: {content}")
                return '\n\n'.join(output)
            
            elif format == 'markdown':
                output = ["# Conversation Export", ""]
                for msg in messages:
                    msg_type = msg.get('type', '')
                    content = msg.get('content', '')
                    
                    if msg_type == 'user':
                        output.append(f"**üë§ Utilisateur:**")
                        output.append(content)
                    elif msg_type == 'assistant':
                        output.append(f"**ü§ñ Assistant:**")
                        output.append(content)
                    output.append("")
                
                return '\n'.join(output)
            
            return None
            
        except Exception as e:
            logger.error(f"Erreur export conversation: {e}")
            return None